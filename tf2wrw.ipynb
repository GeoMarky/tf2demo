{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "tf2wrw.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mdavydenko/tf2demo/blob/master/tf2wrw.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "27u_WiVLr21S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# To determine which version you're using:\n",
        "!pip show tensorflow\n",
        "\n",
        "# For the current version: \n",
        "!pip install --upgrade tensorflow\n",
        "\n",
        "# For a specific version:\n",
        "!pip install tensorflow==2.0.0-alpha0 "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "36Qt0_Aqrj5N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow import keras\n",
        "from datetime import datetime\n",
        "\n",
        "from tensorflow.linalg import expm, sqrtm\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import math as m\n",
        "\n",
        "def ricker(f, nf, df=0.001):\n",
        "    w = df*np.arange(nf,dtype=np.complex64);\n",
        "    y=w*w/f/f/f/m.sqrt(m.pi)*np.exp(-w*w/f/f)\n",
        "    return np.transpose(y+1j*0*y)\n",
        "\n",
        "def Imaging(dx,df,P,Pplu,C):\n",
        "    nz=C.shape[0]\n",
        "    nfreq=P.shape[1]\n",
        "    nx=P.shape[0]\n",
        "    omega=1+2*m.pi*df*np.arange(0,nfreq)\n",
        "    grad = np.zeros([nx,nz], dtype=np.complex64)\n",
        "    Grad  = tf.Variable(grad)\n",
        "    print(P.shape[0])\n",
        "    k_x=np.hstack((np.arange(0,(nx/2)),np.arange(-(nx/2),-1)))*2*m.pi/nx/dx\n",
        "    print(omega.shape)\n",
        "    [fk_k,fk_f]=np.complex64(np.meshgrid(k_x, omega))\n",
        "    for iz in range(nz-1):\n",
        "        kz=tf.math.sqrt(fk_f*fk_f/(C[iz]*C[iz])-fk_k*fk_k)\n",
        "        P=tf.transpose(tf.signal.ifft(tf.math.conj(tf.exp(-1j*dz*tf.math.conj(kz)))*tf.signal.fft(tf.transpose(P))))\n",
        "        Grad[:,iz+1].assign(tf.reduce_mean(P*tf.math.conj(tf.squeeze(P_plu[:,iz+1,:])),axis=1))\n",
        "\n",
        "    return -Grad\n",
        "\n",
        "\n",
        "#@tf.function\n",
        "def FWMod(nmod,down,up,dx,df,P,S,Pplu,Pmin,Rup,Rdown,Tup,Tdown,C):\n",
        "    nz=C.shape[1]\n",
        "\n",
        "    nfreq=P.shape[0]\n",
        "    nx=P.shape[1]\n",
        "    omega=1+2*m.pi*df*np.arange(0,nfreq)\n",
        "\n",
        "    k_x=np.hstack((np.arange(0,(nx/2)),np.arange(-(nx/2),-1)))*2*m.pi/nx/dx\n",
        "    x=np.arange(nx)\n",
        "    [fk_k,fk_f]=np.complex64(np.meshgrid(k_x, omega))\n",
        "    [x,om]=np.complex64(np.meshgrid(x, omega))\n",
        "    om=tf.reshape(tf.tile(om,[1,nx]),[nfreq,nx,nx])\n",
        "\n",
        "    h2dx=np.eye(nx,nx,1,dtype=np.complex64)/dx/dx-2*np.eye(nx,dtype=np.complex64)/dx/dx+np.eye(nx,nx,-1,dtype=np.complex64)/dx/dx\n",
        "    H2dx = tf.Variable(h2dx)\n",
        "    H2dx = tf.reshape(tf.tile(H2dx,[nfreq,1]),[nfreq,nx,nx])\n",
        "\n",
        "    print(om.shape)\n",
        "    extr=1\n",
        "\n",
        "    for imod in range(nmod):\n",
        "        print(imod)\n",
        "        P=S\n",
        "        Pp=S\n",
        "        #with tf.name_scope('rountrip_down'):\n",
        "        if down:\n",
        "            print('down')\n",
        "            for iz in range(nz-1):\n",
        "\n",
        "                with tf.name_scope('scattering_down_%d_z_%d' % (imod,iz)):\n",
        "                    P=P+Rdown[:,iz]*Pmin[:,iz,:]+Tup[:,iz]*Pplu[:,iz,:]\n",
        "                    #P=P+tf.transpose(tf.reshape(tf.tile(Rdown[:,iz],[nfreq]),[nfreq,nx]))*tf.squeeze(Pmin[:,iz,:])+tf.transpose(tf.reshape(tf.tile(Tup[:,iz],[nfreq]),[nfreq,nx]))*tf.squeeze(Pplu[:,iz,:])\n",
        "                with tf.name_scope('propagation_down_%d_z_%d' % (imod,iz)):\n",
        "                    if extr==0:\n",
        "                        kz=tf.math.sqrt(fk_f*fk_f/(C[:,iz])-fk_k*fk_k)\n",
        "                        P=tf.signal.ifft(tf.exp(-1j*dz*tf.math.conj(kz))*tf.signal.fft(P),name=\"W-down\")\n",
        "                    if extr==1:\n",
        "                        H2=om*om*tf.eye(nx,batch_shape=[nfreq],dtype=np.complex64)/C[:,iz]+H2dx\n",
        "                        W=tf.linalg.expm(-1j*dz*tf.math.conj(tf.linalg.sqrtm(H2)))\n",
        "                        P=tf.squeeze(tf.matmul(W,tf.reshape(P,[nfreq,nx,1])))\n",
        "\n",
        "                with tf.name_scope('saving_p_plus_%d_z_%d' % (imod,iz)):\n",
        "                    Pplu=Pplu[:,iz+1,:].assign(P,name=\"P_plu\")\n",
        "                    Pp=tf.concat([Pp,P],1,name=\"Pplu_stack\")\n",
        "                    print(Pp.shape)\n",
        "\n",
        "\n",
        "        P=0*P\n",
        "        Pp=tf.reshape(Pp,[nfreq,nz,nx])\n",
        "        #with tf.name_scope('rountrip_up'):\n",
        "        if up:\n",
        "            print('up')\n",
        "\n",
        "            for iz in reversed(range(1,nz)):\n",
        "                #print(\"scat\")\n",
        "                with tf.name_scope('scattering_up_%d_z_%d' % (imod,iz)):\n",
        "                    P=P+Rup[:,iz]*Pp[:,iz,:]+Tdown[:,iz]*Pmin[:,iz,:]\n",
        "                    #P=P+tf.transpose(tf.reshape(tf.tile(Rup[:,iz],[nfreq]),[nfreq,nx]))*tf.squeeze(Pplu[:,iz,:])+tf.transpose(tf.reshape(tf.tile(Tdown[:,iz],[nfreq]),[nfreq,nx]))*tf.squeeze(Pmin[:,iz,:])\n",
        "                    #P=P+tf.transpose(tf.reshape(tf.tile(Rup[:,iz],[nfreq]),[nfreq,nx]))*tf.squeeze(Pp[iz,:,:])+tf.transpose(tf.reshape(tf.tile(Tdown[:,iz],[nfreq]),[nfreq,nx]))*tf.squeeze(Pmin[:,iz,:])\n",
        "                #print(\"prop\")\n",
        "                with tf.name_scope('propagation_up_%d_z_%d' %(imod,iz)):\n",
        "                    if extr==0:\n",
        "                        kz=tf.math.sqrt(fk_f*fk_f/(C[:,iz])-fk_k*fk_k)\n",
        "                        P=tf.signal.ifft(tf.exp(-1j*dz*tf.math.conj(kz))*tf.signal.fft(P),name=\"W-up\")\n",
        "                    if extr==1:\n",
        "                        H2=om*om*tf.eye(nx,batch_shape=[nfreq],dtype=np.complex64)/C[:,iz]+H2dx\n",
        "                        W=tf.linalg.expm(-1j*dz*tf.math.conj(tf.linalg.sqrtm(H2)))\n",
        "                        P=tf.squeeze(tf.matmul(W,tf.reshape(P,[nfreq,nx,1])))\n",
        "                #print(\"save\")\n",
        "                with tf.name_scope('saving_p_minus_%d_z_%d' %(imod,iz)):\n",
        "                    Pmin=Pmin[:,iz-1,:].assign(P,name=\"P_min\")\n",
        "    return P\n",
        "\n",
        "\n",
        "#general parameters\n",
        "ntap=15\n",
        "nx=50\n",
        "dx=10\n",
        "dz=10\n",
        "nt=256\n",
        "dt=0.004\n",
        "nz=50\n",
        "df=1/nt/dt\n",
        "mode=0\n",
        "\n",
        "nfreq=round(nt/2)\n",
        "nfreq=round(30/df)\n",
        "ns=1\n",
        "nmod=3\n",
        "omega=2*m.pi*df*np.arange(1,nfreq)\n",
        "print(omega)\n",
        "#variables\n",
        "c=1500\n",
        "vel = c*np.ones([nx,nz], dtype=np.complex64)\n",
        "\n",
        "rup = np.zeros([nx,nz], dtype=np.complex64)\n",
        "rdown = np.zeros([nx,nz], dtype=np.complex64)\n",
        "tup = np.zeros([nx,nz], dtype=np.complex64)\n",
        "tdown = np.zeros([nx,nz], dtype=np.complex64)\n",
        "\n",
        "mask = np.ones([nx,nz], dtype=np.complex64)\n",
        "for iz in range(10):\n",
        "    mask[:,iz]=0\n",
        "\n",
        "rtrue = np.zeros([nx,nz], dtype=np.complex64)\n",
        "ctrue = c*np.ones([nx,nz], dtype=np.complex64)\n",
        "ctrue=ctrue*ctrue\n",
        "for ix in range(nx):\n",
        "    rtrue[ix,10+round(10*ix/nx)]=0.8\n",
        "    rtrue[ix,40-round(10*ix/nx)]=0.8\n",
        "    if mode==1:\n",
        "        ctrue[ix,10+round(10*ix/nx):40-round(10*ix/nx)]=2000\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "if(mode==1):\n",
        "    rup=rtrue\n",
        "    rdown=-rtrue\n",
        "    tup=rtrue\n",
        "    tdown=-rtrue\n",
        "    vel=ctrue\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "vel=ctrue\n",
        "\n",
        "plt.imshow(np.abs(vel))\n",
        "plt.show()\n",
        "\n",
        "C   =  tf.Variable(vel,name=\"velocity\")\n",
        "C0   = tf.Variable(vel)\n",
        "\n",
        "p_plus = np.zeros([nfreq,nx,nz], dtype=np.complex64)\n",
        "p_minus = np.zeros([nfreq,nx,nz], dtype=np.complex64)\n",
        "p = np.zeros([nfreq,nx], dtype=np.complex64)\n",
        "p[:,round(nx/2)]=100*ricker(30,nfreq,df)\n",
        "\n",
        "P_plu  = tf.Variable(p_plus,name=\"Pplu\")\n",
        "P_min = tf.Variable(p_minus,name=\"Pmin\")\n",
        "S = tf.Variable(p,name=\"wavefield\")\n",
        "P = tf.Variable(p,name=\"wavefield\")\n",
        "\n",
        "Rup = tf.Variable(rup,name=\"reflectivity\")\n",
        "Gup = tf.Variable(rup,name=\"reflectivity\")\n",
        "Rdown = tf.Variable(rdown,name=\"reflectivity\")\n",
        "Tup = tf.Variable(tup,name=\"reflectivity\")\n",
        "Tdown = tf.Variable(tdown,name=\"reflectivity\")\n",
        "\n",
        "\n",
        "Mask = tf.Variable(mask,name=\"reflectivity\")\n",
        "\n",
        "\n",
        "\n",
        "def loss(Rup,C,Pobs):\n",
        "  Res = fwmod(R,C) - Pobs\n",
        "  return tf.reduce_mean(Res*tf.math.conj(Res)),Res\n",
        "\n",
        "if mode==1:\n",
        "    #tf.summary.trace_on(graph=True, profiler=True)\n",
        "    P=FWMod(nmod,1,1,dx,df,P,S,P_plu,P_min,Rup,-Rup,Tup,Tdown,C)\n",
        "    #with writer.as_default():\n",
        "    #    tf.summary.trace_export(name=\"my_func_trace\",step=0,profiler_outdir=logdir)\n",
        "\n",
        "    np.save(\"pobs\",P.numpy())\n",
        "    plt.imshow(np.fft.irfft(P.numpy(),n=nt,axis=0))\n",
        "    plt.show()\n",
        "if mode==0:\n",
        "    loss_history = []\n",
        "    for i in range(30):\n",
        "        pobs=np.load(\"pobs.npy\")\n",
        "        Pobs=tf.Variable(pobs,name=\"observed\")\n",
        "        with tf.GradientTape(persistent=True) as tape:\n",
        "          #tape.watch(C)\n",
        "          Res=Pobs-FWMod(nmod,1,1,dx,df,P,S,P_plu,P_min,Rup,Rdown,Tup,Tdown,C)\n",
        "          #Res=Pobs*tf.math.conj(FWMod(nmod,1,1,dx,df,P,S,P_plu,P_min,Rup,Rdown,Tup,Tdown,C))\n",
        "          #loss=tf.reduce_mean(Res*tf.math.conj(Res))+0.1*tf.reduce_mean((Rup+Rdown)*(Rup+Rdown))\n",
        "          #pen=0.00001*tf.reduce_mean(tf.math.log(1+tf.math.multiply(Rup,Rup)/0.05/0.05)*tf.math.log(1+tf.math.multiply(Rup,Rup)/0.05/0.05))\n",
        "          loss=tf.reduce_mean(Res*tf.math.conj(Res))#+pen\n",
        "\n",
        "        plt.figure(150)\n",
        "        plt.clf()\n",
        "        plt.imshow(np.fft.irfft(Res.numpy(),n=nt,axis=0))\n",
        "        plt.pause(1)\n",
        "        #gradpen=tape.gradient(pen, Rup)\n",
        "        #grad_down=tape.gradient(loss, Rdown)\n",
        "        grad=tape.gradient(loss, Rup)\n",
        "        gradvel=tape.gradient(loss, C)\n",
        "        #grad_tup=tape.gradient(loss, Tup)\n",
        "        #grad_tdown=tape.gradient(loss, Tdown)\n",
        "        #grad=Imaging(dx,df,Res,P_plu,C)\n",
        "\n",
        "        loss_value=tf.reduce_mean(Res*tf.math.conj(Res))\n",
        "        loss_history.append(loss_value.numpy())\n",
        "        print(\"Current loss: {:.10f}\".format(loss_value))\n",
        "\n",
        "        #plt.figure(200)\n",
        "        #plt.clf()\n",
        "        #plt.imshow(np.transpose(np.real(Grad0.numpy())))\n",
        "\n",
        "        plt.figure(201)\n",
        "        plt.clf()\n",
        "        plt.imshow(np.transpose(np.real(grad.numpy())))\n",
        "        plt.pause(1)\n",
        "        plt.figure(2011)\n",
        "        plt.clf()\n",
        "        plt.imshow(np.transpose(np.real(gradvel.numpy())))\n",
        "        plt.pause(1)\n",
        "\n",
        "\n",
        "        grad=Mask*(grad+tf.math.conj(grad))\n",
        "        #grad_down=Mask*(grad_down+tf.math.conj(grad_down))\n",
        "        #grad_tup=Mask*(grad_tup+tf.math.conj(grad_tup))\n",
        "        #grad_tdown=Mask*(grad_tdown+tf.math.conj(grad_tdown))\n",
        "\n",
        "        P_min.assign(0*P_min)\n",
        "        P_plu.assign(0*P_plu)\n",
        "        Psca=FWMod(1,1,1,dx,df,P,S,P_plu,P_min,grad,Rdown,Tup,Tdown,C)\n",
        "        P_min.assign(0*P_min)\n",
        "        P_plu.assign(0*P_plu)\n",
        "\n",
        "        asum=tf.reduce_mean(Psca*tf.math.conj(Res))+tf.reduce_mean(Res*tf.math.conj(Psca))\n",
        "        dsum=tf.reduce_mean(Psca*tf.math.conj(Psca))+tf.reduce_mean(Psca*tf.math.conj(Psca))\n",
        "        Rup.assign_add(asum/dsum*grad)\n",
        "        Rdown.assign_add(-asum/dsum*grad)\n",
        "        Tup.assign_add(asum/dsum*grad)\n",
        "        Tdown.assign_add(-asum/dsum*grad)\n",
        "\n",
        "        plt.figure(202)\n",
        "        plt.clf()\n",
        "        plt.imshow(np.transpose(np.real(Rup.numpy())))\n",
        "        plt.pause(1)\n",
        "\n",
        "\n",
        "    plt.show()\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}